# Udacity Data Engineering with AWS Nanodegree

![Udacity Logo](logo/Udacity_Logo_2024.png)

## Program Overview

The **Data Engineering with AWS Nanodegree** is a 4-month intermediate-level program focused on building job-ready skills in data engineering. It covers relational and NoSQL data modeling, cloud-based data warehouses, data lakes, and pipeline automation using tools like Apache Cassandra, Spark, Airflow, and AWS services (S3, Redshift, Glue, Athena).

### Learning Objectives
- Create user-friendly relational and NoSQL data models.
- Build scalable and efficient data warehouses.
- Work with massive datasets effectively.
- Develop and manage cloud-based data lakes.
- Automate and monitor data pipelines.
- Gain proficiency in Spark, Airflow, and AWS tools.

### Prerequisites
- Intermediate Python
- Intermediate SQL
- Command-line skills



---

## Repository Structure

This repository is organized by project, corresponding to the four courses in the Nanodegree:

- **`data_modeling_with_apache_cassandra/`**
  - Course 1 Project: *Data Modeling with Apache Cassandra*
  - Description: Code for creating a non-relational database and ETL pipeline for a music streaming app using Apache Cassandra.

- **`data_warehouse/`**
  - Course 2 Project: *Data Warehouse*
  - Description: ELT pipeline scripts to extract data from S3, stage it in Redshift, and transform it into dimensional tables for analytics.

- **`stedi_human_balance_analysis/`**
  - Course 3 Project: *STEDI Human Balance Analytics*
  - Description: Data lakehouse solution for sensor data using Spark and AWS Glue, including an ELT pipeline to process data into analytics tables.

- **`data_pipelines_with_airflow/`**
  - Course 4 Project: *Data Pipelines with Airflow*
  - Description: Apache Airflow DAGs and operators to build reusable data pipelines for a music streaming company, processing data from S3 to Redshift.

---

## Courses and Projects

### Course 1: Data Modeling
- **Focus**: Relational and NoSQL data modeling with Apache Cassandra.
- **Project**: Build an ETL pipeline and non-relational database for a music streaming app.
- **Folder**: `data_modeling_with_apache_cassandra/`

### Course 2: Cloud Data Warehouses
- **Focus**: Data warehousing on AWS with Redshift and S3.
- **Project**: Create an ELT pipeline to transform S3 data into Redshift dimensional tables.
- **Folder**: `data_warehouse/`

### Course 3: Spark & Data Lakes
- **Focus**: Big data processing with Spark and data lakehouse architecture on AWS.
- **Project**: Develop an ELT pipeline for sensor data using Spark and AWS Glue.
- **Folder**: `stedi_human_balance_analysis/`

### Course 4: Automate Data Pipelines
- **Focus**: Pipeline automation with Apache Airflow and AWS.
- **Project**: Build reusable data pipelines for a music streaming company using Airflow and Redshift.
- **Folder**: `data_pipelines_with_airflow/`

---

## Tools and Technologies
- **Programming**: Python, SQL
- **Databases**: Apache Cassandra, Amazon Redshift
- **Big Data**: Apache Spark
- **Workflow**: Apache Airflow
- **AWS Services**: S3, Redshift, Glue, Athena
- **Other**: ETL/ELT, Data Lakehouse Architecture

---
